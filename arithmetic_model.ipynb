{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomtomh512/Handwritten-Arithmetic-Calculator-v2/blob/main/arithmetic_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYubc6-iqKqG",
        "outputId": "e565d475-7fb5-4f57-b97c-5c9fe3a88dd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.4)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.6.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.7)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FH9e-b8h7_xg"
      },
      "outputs": [],
      "source": [
        "import opendatasets as od\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import pair_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_JDrcD381h9",
        "outputId": "df5e6876-dfca-4d8a-a344-1b9d0e7fd3fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/sagyamthapa/handwritten-math-symbols\n",
            "Downloading handwritten-math-symbols.zip to ./handwritten-math-symbols\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39.4M/39.4M [00:00<00:00, 95.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "od.download(\"https://www.kaggle.com/datasets/sagyamthapa/handwritten-math-symbols/data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove variables"
      ],
      "metadata": {
        "id": "L9LohvS0FAtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/handwritten-math-symbols/dataset/x\n",
        "!rm -r /content/handwritten-math-symbols/dataset/y\n",
        "!rm -r /content/handwritten-math-symbols/dataset/z"
      ],
      "metadata": {
        "id": "nz315Kkl5Cev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndRljeIMJ_FR"
      },
      "source": [
        "Transform composition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWdMMuiD9Ni-"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "  transforms.Resize((128, 128)),          # Resize to a 128x128\n",
        "  transforms.Grayscale(),                 # Convert to grayscale\n",
        "  transforms.ToTensor(),                  # Convert to tensor\n",
        "  transforms.Normalize([0.5], [0.5])      # Normalize\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yXoIYAuJ7hO"
      },
      "source": [
        " Train and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-g1nfky9YI-"
      },
      "outputs": [],
      "source": [
        "train_data = datasets.ImageFolder(root='/content/handwritten-math-symbols/dataset', transform=transform)\n",
        "test_data = datasets.ImageFolder(root='/content/handwritten-math-symbols/dataset', transform=transform)\n",
        "train_loader = DataLoader(train_data, batch_size = 30, shuffle = True)\n",
        "test_loader = DataLoader(test_data, batch_size = 30, shuffle = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Uzx6UXSKDZm"
      },
      "source": [
        "Convolutional Network class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1R4KOnv9nlG"
      },
      "outputs": [],
      "source": [
        "class ConvolutionalNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, 1)       # input, output, kernel, stride\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "    self.conv3 = nn.Conv2d(64, 128, 3, 1)\n",
        "    self.conv4 = nn.Conv2d(128, 256, 3, 1)\n",
        "\n",
        "    self.fc1 = nn.Linear(256 * 6 * 6, 512)    # 256 * 6 * 6 -> 512\n",
        "    self.fc2 = nn.Linear(512, 256)\n",
        "    self.fc3 = nn.Linear(256, 128)\n",
        "    self.fc4 = nn.Linear(128, 16)\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = F.relu(self.conv1(X))\n",
        "    X = F.max_pool2d(X, 2, 2)\n",
        "    X = F.relu(self.conv2(X))\n",
        "    X = F.max_pool2d(X, 2, 2)\n",
        "    X = F.relu(self.conv3(X))\n",
        "    X = F.max_pool2d(X, 2, 2)\n",
        "    X = F.relu(self.conv4(X))\n",
        "    X = F.max_pool2d(X, 2, 2)\n",
        "\n",
        "    X = X.view(-1, 256 * 6 * 6)\n",
        "\n",
        "    X = F.relu(self.fc1(X))\n",
        "    X = F.relu(self.fc2(X))\n",
        "    X = F.relu(self.fc3(X))\n",
        "    X = self.fc4(X)\n",
        "\n",
        "    return F.log_softmax(X, dim = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciQBNe8eKHMR"
      },
      "source": [
        "Create CNN object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYp8EyQd9qmj"
      },
      "outputs": [],
      "source": [
        "model = ConvolutionalNetwork()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPAwDBRfKU91"
      },
      "source": [
        "Using Cross Entropy and Adam Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06Ggb8MX9rmx"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qt8lFdsSKdAC"
      },
      "source": [
        "Training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBzmcycKMPWZ",
        "outputId": "0cbe2ca5-9bc3-487d-ef29-e8e4352abcb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 1.181\n",
            "Epoch 2/5, Loss: 0.295\n",
            "Epoch 3/5, Loss: 0.150\n",
            "Epoch 4/5, Loss: 0.100\n",
            "Epoch 5/5, Loss: 0.080\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    images, labels = data\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # images.size(0) = number of samples in batch, total loss for batch\n",
        "    running_loss += loss.item() * images.size(0)\n",
        "\n",
        "  epoch_loss = running_loss / len(train_loader.dataset)\n",
        "  print(f'Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss:.3f}')\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5F9KDApORb2"
      },
      "source": [
        "Calculate Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2leNzrKP7z7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba969a70-9255-41c8-81d3-e79bdf1e9634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 99.356%\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i, data in enumerate(test_loader, 0):\n",
        "    images, labels = data\n",
        "\n",
        "    outputs = model(images)\n",
        "    predicted = outputs.argmax(dim=1)\n",
        "    total += labels.size(0)\n",
        "\n",
        "    # Count number of matches\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total * 100\n",
        "print(f'Accuracy: {accuracy:.3f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpxMm3jFOOAi"
      },
      "source": [
        "Save model state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmfCftBwFYi6"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'math_model_0.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Evl-PkoEOT0q"
      },
      "source": [
        "Testing CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6Dfw89M9ud7"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image_path):\n",
        "    image = Image.open(image_path).convert('L')     # 'L' = Single channel image, grayscale\n",
        "    transform = transforms.Compose([                # Match transform composition\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.Grayscale(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5], [0.5])\n",
        "    ])\n",
        "    image = transform(image)\n",
        "    return image\n",
        "\n",
        "image_path = '/content/handwritten-math-symbols/dataset/5/1102.jpg'\n",
        "processed_image = preprocess_image(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuGJk_V-GgC0",
        "outputId": "159fa5b3-6ca8-4398-8490-a7783ac129d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5)\n"
          ]
        }
      ],
      "source": [
        "processed_image = processed_image.unsqueeze(0)  # Add batch dimension\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    new_prediction = model(processed_image)\n",
        "\n",
        "print(new_prediction.argmax())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}